---
title: "Modelagem do Pr√™mio frequ√™ncia-severidade por Bullman-Straub, Random Forest e XGboost com grupos tarif√°rios agrupados pelo algoritmo k-means"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
Sys.setlocale("LC_ALL", "en_US.UTF-8")
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(patchwork)
library(ggplot2)
library(knitr)
library(kableExtra)
library(stringi)
library(tidyr)
library(gridExtra)
library(ggplot2)
library(rsample)
library(rstan)
library(randomForest)
library(xgboost)
library(caret)
library(cluster)
library(stats)
library(thematic)
library(tidyverse)
library(plotly)
library(kableExtra)
library(gridExtra)
library(xtable)
library(reshape2)
library(rstan)  ### para utilizacao de inferencia bayesiana
library(bayesplot)
```

# Introdu√ß√£o

Este trabalho utiliza dados extra√≠dos do sistema AUTOSEG, disponibilizado pela Superintend√™ncia de Seguros Privados (SUSEP), referentes ao modelo de ve√≠culo Hyundai HB20, nos anos de 2017, 2018, 2019 e 2020.
Ressalta-se que os dados referentes ao ano de 2016 n√£o estavam dispon√≠veis no sistema no momento da extra√ß√£o das informa√ß√µes, por isso n√£o foi considerado.

O sistema AUTOSEG permite a realiza√ß√£o de consultas on-line sobre dados estat√≠sticos do seguro de autom√≥veis. As informa√ß√µes disponibilizadas t√™m como base os arquivos enviados semestralmente pelas seguradoras, conforme previsto no item 9 do Manual de Orienta√ß√£o anexo √† Circular SUSEP n¬∫ 522/2015, abrangendo dados de ap√≥lices vigentes e sinistros ocorridos durante o per√≠odo analisado.


## Carregar dados

```{r}
df_regiao <- read.csv("C:/P√≥s em Atu√°ria/Trabalho de Conclus√£o de Curso/Analise/Base/HB20_2017-2020_Agrupada_Regiao.csv", encoding = "UTF-8")
df_regiao_ano <- read.csv("C:/P√≥s em Atu√°ria/Trabalho de Conclus√£o de Curso/Analise/Base/HB20_2017-2020_Agrupado_Regiao_Ano.csv", encoding = "UTF-8")
```

A base de dados analisada √© composta por 1640 observa√ß√µes e 16 vari√°veis, conforme descritas a seguir:
  
  * Ano: Ano de ocorr√™ncia do dado;

* Categoria: Categoria do ve√≠culo segurado;

* Regi√£o: Unidade da federa√ß√£o ou regi√£o onde o seguro foi contratado;

* Grupo: Identifica√ß√£o do modelo do ve√≠culo;

* Ano_Modelo: Ano de fabrica√ß√£o/modelo do ve√≠culo;

* Sexo: Sexo do condutor principal;

* Faixa_Et√°ria: Faixa et√°ria do condutor principal;

* IS_Media.RS.: Import√¢ncia segurada m√©dia, em reais;

* Expostos: Quantidade de exposi√ß√µes ao risco (ve√≠culos-seguro);

* Premio_Medio.RS.: Pr√™mio m√©dio pago pelo seguro, em reais;

* Freq_Inc_Roubo: Frequ√™ncia de sinistros por roubo ou furto;

* Ind_Inc_Roubo.RS.: Indeniza√ß√£o paga por sinistros de roubo ou furto, em reais;

* Freq_Colisao: Frequ√™ncia de sinistros por colis√£o;

* Ind_Colisao.RS.: Indeniza√ß√£o paga por sinistros de colis√£o, em reais;

* Freq_Outros: Frequ√™ncia de sinistros classificados como outros;

* Ind_Outras.RS.: Indeniza√ß√£o paga por sinistros classificados como outros, em reais.


## 2. Medidas de avalia√ß√£o de risco


A partir da an√°lise dos dados de sinistro, ap√≥s  identificar possiveis grupos de risco para segregar os dados em classes, foram observadas as razoes de Sinistros/Expostos mensais e Raz√µes Frequ√™ncia para o grupamento por regi√£o.
  
# Classifica√ß√£o utilizando k-means

# ==================================================
# AGRUPAMENTO POR GRUPO DE RISCO UTILIZANDO K-MEANS
# ==================================================
## Necess√°rio para identificar as regioes de alto, medio e baixo √çndice de colis√£o 

``` {r}
# Executar k-means sobre a vari√°vel Razao
kmeans_resultado <- kmeans(df_regiao$Razao, centers = 3)

# Adicionar o grupo tarif√°rio ao dataframe
df_aux2 <- df_regiao %>%
  ungroup() %>%  # <- ESSENCIAL
  mutate(GrupoTarifario_km = as.factor(kmeans_resultado$cluster))
# Ordenar os clusters por m√©dia da raz√£o
cluster_ordem <- df_aux2 %>%
  group_by(GrupoTarifario_km) %>%
  summarise(media = mean(Razao)) %>%
  arrange(media) %>%
  mutate(novo_grupo = paste0("T", row_number()))

# Juntar novamente com o dataframe original
df_aux2 <- df_aux2 %>%
  left_join(cluster_ordem %>% select(GrupoTarifario_km, novo_grupo),
            by = "GrupoTarifario_km") %>%
  rename(GrupoTarifario_km_Num = GrupoTarifario_km,
         GrupoTarifario_km = novo_grupo)
write.csv(df_aux2, "C:/P√≥s em Atu√°ria/Trabalho de Conclus√£o de Curso/Analise/Base/HB20_2017-2020_Ajustado_Regiao_kmeans.csv", row.names = FALSE)
```

# ==========================================
# AGRUPANDO POR GRUPOS TARIFARIOS - Kmeans
# ==========================================
```{r}
grupoAlt = unique((df_aux2 %>% filter(GrupoTarifario_km == "T3"))$Regiao) # alto indice de colis√£o
grupoMed = unique((df_aux2 %>% filter(GrupoTarifario_km == "T2"))$Regiao) # medio indice de colis√£o
grupoBai = unique((df_aux2 %>% filter(GrupoTarifario_km == "T1"))$Regiao) # baixo indice de colis√£o

df = df_regiao_ano %>%
  mutate(Grupo_Tarifario = case_when(
    Regiao %in% grupoAlt ~ "Alto",
    Regiao %in% grupoMed ~ "Medio",
    Regiao %in% grupoBai ~ "Baixo")) %>%
  group_by(Grupo_Tarifario, Ano) %>%
  summarise(Expostos = sum(Expostos),
            Freq_Total = sum(Freq_Total),
            Ind_Total = sum(Ind_Total)) %>%
  mutate(Frequencia = Freq_Total / Expostos,
         Severidade = case_when(
           Freq_Total > 0 ~ Ind_Total/Freq_Total,
           TRUE ~ 0),
         Razao = Ind_Total / Expostos)
View(df)
```

### 3.2.1 An√°lise Explorat√≥ria por Classe de Riscos

```{r, echo=FALSE}
## Analise exploratoria dos dados ap√≥s a escolha dos grupos
df_1 = df %>%
  arrange(match(Grupo_Tarifario, c("Alto", "Medio", "Baixo")))  %>%
  mutate(Severidade = round(Severidade, 2)) %>%
  mutate(Razao = round(Razao, 1)) %>%
  ungroup()

df_1g = df_1
df_1 = df_1 %>% select(-Grupo_Tarifario)

g1 = ggplot(data = filter(df_1g, Ano != "2020"),
            mapping = aes(x = reorder(Grupo_Tarifario, Frequencia),
                          y = Frequencia)) +
  geom_boxplot(alpha = 0.6, col = "blue") +
  xlab("")+
  ylab("Frequencia / Expostos")+
  labs(subtitle = "Frequencia (por grupo tarifario)")

g2 = ggplot(data = filter(df_1g, Ano != "2020"),
            mapping = aes( x = reorder(Grupo_Tarifario, Severidade),
                          y = Severidade)) +
  geom_boxplot(alpha = 0.6, col = "red") +
  xlab("")+
  ylab("Indenizacoes / Frequencia")+
  labs(subtitle = "Indenizacoes (por grupo tarifario)")

grid.arrange(g1, g2, ncol=2)

dados_sev = df
```

### Vers√£o Bayesiana do modelo de B√ºhlmann-Straub
# ======================
# ===== SEVERIDADE =====
# ======================

```{r}
## dados para severidade experi√™ncia do analista
df = dados_sev %>%
  filter(Ano != 2020)

alto.BS = df$Severidade[df$Grupo_Tarifario == "Alto"]
medio.BS = df$Severidade[df$Grupo_Tarifario == "Medio"]
baixo.BS = df$Severidade[df$Grupo_Tarifario == "Baixo"]

M2 = matrix(c(alto.BS, medio.BS, baixo.BS), byrow = TRUE, ncol = 3)
colnames(M2) = c("2017", "2018", "2019")
rownames(M2) = c("Alto", "Medio", "Baixo")
M2

```

```{r}

#model <- stan_model("bulhmann-straub-severidade-02.stan")

# ----------------------
# ---- rodando stan ----
# ----------------------

options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)

stan.dados <- list(x = M2, m = 3, n = 3)   # dados que entram no modelo

amostras <- stan("C:/P√≥s em Atu√°ria/Trabalho de Conclus√£o de Curso/Analise/Base/bulhmann-straub-severidade-02.stan",
                 data = stan.dados,
                 warmup = 30000,
                 control = list(adapt_delta=0.999),
                 iter = 100000,
                 thin = 30,
                 chains = 2)

```
A implementa√ß√£o foi realizada em linguagem Stan, utilizando o algoritmo HMC (Hamiltonian Monte Carlo). Foram adotadas 100.000 itera√ß√µes por cadeia, com descarte de 30.000 para *warmup*, al√©m de um *thin* de 30 e duas cadeias em paralelo. 

## 4.6 An√°lise das Sa√≠das e Diagn√≥stico das Cadeias de Markov

```{r}
# ---------------------------
# ---- analisando saidas ----
# ---------------------------
s.post <- extract(amostras)   # transforma as saidas (objeto do rstan) em listas do R
names(s.post)

saveRDS(s.post,"output-bulhmann-straub-severidade-ajustado.rds")

mu.s<- s.post$mu # premio de credibilidade

## o erro padr√£o
std.error.post<- apply(s.post$mu, 2, sd)
std.error.post
```
As estimativas posteriores para os pr√™mios de credibilidade (`mu`) foram obtidas a partir da simula√ß√£o via MCMC. Os valores constam na tabela std.error.post

Esses valores indicam o grau de incerteza associado a cada estimativa de `mu`. Observa-se que os erros padr√£o s√£o relativamente elevados, o que est√° em linha com os alertas emitidos durante a execu√ß√£o do modelo.

```{r traceplot-mu, echo=FALSE, fig.width=12, fig.height=4, fig.align='center', fig.cap="Traceplot das cadeias MCMC para os grupos Alto, M√©dio e Baixo"}

colnames(mu.s) <- c("Alto", "M√©dio", "Baixo")

color_scheme_set("brightblue")

mcmc_trace(mu.s) + 
  theme_bw() + 
  theme(legend.position = "bottom")

# avalia converg√™ncia das cadeias do MCMC

summary(amostras)$summary[, "Rhat"]

```

```{r}

## densidade a posteriori
color_scheme_set("brightblue")
colnames(mu.s)<- c('Alto', 'M√©dio', 'Baixo')
mcmc_areas(mu.s, prob=0.95, point_est="mean")+ theme_bw() +
  labs(x = "valor do sinistro", y = "grupos de risco", title = NULL) 

## intervalos de credibilidade de 95%
q025<- function(x){quantile(x,0.025)}
q975<- function(x){quantile(x,0.975)}

summary.post<- data.frame(Pbayes= apply(s.post$mu,2,median),
                          lowerIC= apply(s.post$mu, 2, q025), upperIC= apply(s.post$mu, 2, q975))
summary.post

### estimativa pontual a posteriori e intervalo de credibilidade
color_scheme_set("brightblue")
mcmc_intervals(mu.s, point_est="mean", inner_size=0.025, outer_size=0.975) + theme_bw() +
  labs(x = "grupos de risco", y = "valor do sinistro", title = "Pr√™mio de Bayes (IC 95%)") +
  geom_point(aes(x=summary.post$Pbayes,y=3:1), col="lightgreen", size=3) 

### autocorrelacao das cadeias
acf(s.post$mu[,1])
acf(s.post$mu[,2])
acf(s.post$mu[,3])
acf(s.post$sigma2vet[,1])
acf(s.post$sigma2vet[,2])
acf(s.post$sigma2vet[,3])
acf(s.post$mu0)

### estimativa pontual 
summary(s.post$mu[,1])  ### Pcred.1 bayes
summary(s.post$mu[,2])  ### Pcred.2 bayes
summary(s.post$mu[,3])  ### Pcred.3 bayes

summary(s.post$sigma2vet[,1])
summary(s.post$sigma2vet[,2])
summary(s.post$sigma2vet[,3])

# COLETIVO
summary(s.post$mu0)  ### coletivo

boxplot(t(M2), ylab="valor pago", cex=1.5, cex.lab=1.5,cex.axis=1.5)

summary(s.post$w[,1])
summary(s.post$w[,2])
summary(s.post$w[,3])

Pcred1 = median(s.post$mu[,1])
Pcred2 = median(s.post$mu[,2])
Pcred3 = median(s.post$mu[,3])

w1 = median(s.post$w[,1])
w2 = median(s.post$w[,2])
w3 = median(s.post$w[,3])

w=c(w1,w2,w3)
w

Pcol = median(s.post$mu0)

Pind1 = (Pcred1 - (1-w1)*Pcol)/w1
Pind2 = (Pcred2 - (1-w2)*Pcol)/w2
Pind3 = (Pcred3 - (1-w3)*Pcol)/w3

# Resultado tabelado

df_sev <- summary.post %>% mutate(
  Grupo = c("Alto", "M√©dio", "Baixo"),
  Premio_Individual = c(Pind1, Pind2, Pind3),
  Premio_Coletivo = rep(Pcol, 3),
  Premio_Credibilidade = Pbayes
) %>% select(Grupo, Premio_Individual, Premio_Coletivo, Premio_Credibilidade, lowerIC, upperIC)
df_sev

```
A densidade a posteriori tem um comportamento de distibui√ß√£o normal, conforme distribui√ß√µes a priori consideradas para a modelagem da severidade de sinsitros. 

A densidade a posteriori oferece uma vis√£o completa da incerteza e variabilidade dos par√¢metros ap√≥s a an√°lise dos dados, e o summary post fornece um resumo quantitativo dessa informa√ß√£o para facilitar a interpreta√ß√£o e a tomada de decis√µes. O summary post apresentado mostra o Premio de Bayes, que √© a m√©dia da distribui√ß√£o a posteriori para o par√¢metro mu de cada grupo e os seus limites m√≠nimos e m√°ximos do intervalo de credibilidade de 95% para mu. Isso significa que h√° uma probabilidade de 95% de que o verdadeiro valor de mu esteja dentro desse intervalo, tendo em vista os dados observados e a distribui√ß√£o a priori assumida. A tabela tamb√©m classifica os Pr√™mios de Bayes e os seus respectivos intervalos por classe de Risco Alta, M√©dia e Baixo dos Grupos Tarif√°rios. Os intervalos de credibilidade n√£o apresentam diferen√ßas estat√≠sticamente significativas, mas h√° uma diferen√ßa na m√©dia obtida para os diferentes Grupos de Risco.

Em rela√ß√£o √†s autocorrela√ß√µes das cadeias, os gr√°ficos de autocorrela√ß√£o mostram uma queda r√°pida para valores pr√≥ximos de zero, indicando que a cadeia est√° se misturando bem e fornecendo estimativas precisas para theta, pois uma autocorrela√ß√£o baixa sugere que as amostras s√£o menos dependentes entre si. J√° para o fator de credibilidade (w), os gr√°ficos mostram que h√° uma baixa autocorrela√ß√£o, logo, a cadeia est√° explorando eficientemente o espa√ßo amostral para w, resultando em estimativas mais confi√°veis j√° que as amostras de w s√£o aproximadamente independentes. Para mu0, a FAC (Fun√ß√£o de Autocorrela√ß√£o) mostra que h√° depend√™ncia at√© aproximadamente a terceira amostra de mu0, indicando que existe algum grau de depend√™ncia entre as amostras do par√¢metro global.

As estimativas pontuais para w e para mu apresentam os instantes amostrais dos par√¢metros para os 3 grupos tarif√°rios: Alto, M√©dio e Baixo. Pode-se notar que a mediana √© ligeiramente superior √† m√©dia dos grupos tarif√°rios alto, m√©dio e baixo para os par√¢metros mu. O sigma2 indica os erros e apesar de existir um vari√¢ncia elevada, ao se levar em conta a magnitude dos dados, tais erros s√£o aceit√°veis. Em rela√ß√£o ao mu0, observam-se valores de instantes amostrais mais altos, por refletir uma m√©dia global do par√¢metro mu no modelo. Al√©m disso, ao avaliar os valores de m√©dia e mediana, v√™-se que s√£o bem pr√≥ximos. Para esse estudo, optou-se por utilizar a mediana para as estimativas.

Os fatores de credibilidade aproximam-se mais de 1 que de 0 para o Grupo Tarif√°rio de Baixo Risco e de 0 para os Grupos Tarif√°rios de Alto e M√©dio Risco, o que indica que para o primeiro h√° maior peso atribu√≠do √† experi√™ncia individual de cada grupo na estimativa do pr√™mio de seguro, em compara√ß√£o com a m√©dia coletiva, enquanto para os outros Grupos h√° maior peso atribu√≠do √† m√©dia coletiva. √â poss√≠vel notar que o fator de credibilidade √© maior para o Grupo tarif√°rio de baixo risco em compara√ß√£o aos de M√©dio e Alto Risco. Al√©m disso, com fatores de credibilidade em torno de 0,50 para os Grupos Alto e M√©dio, os pr√™mios de credibilidade calculados para cada grupo est√£o recebendo pesos aproximadamente iguais baseados na experi√™ncia individual do grupo e na m√©dia coletiva. Ainda assim, h√° uma maior pondera√ß√£o da experi√™ncia individual da classe de Baixo Risco sendo atribu√≠da aos valores dos premios de credibilidade obtidos para essa classe.

# ========================================
# FREQU√äNCIA
# ========================================

## Carregar dados

```{r}
df_regiao <- read.csv("C:/P√≥s em Atu√°ria/Trabalho de Conclus√£o de Curso/Analise/Base/HB20_2017-2020_Ajustado_Regiao_kmeans.csv", encoding = "UTF-8")
df_regiao_ano <- read.csv("C:/P√≥s em Atu√°ria/Trabalho de Conclus√£o de Curso/Analise/Base/HB20_2017-2020_Agrupado_Regiao_Ano.csv", encoding = "UTF-8")
```

A seguir, as regi√µes foram categorizadas em tr√™s grupos tarif√°rios (Alto, M√©dio e Baixo) por meio do algoritmo K-means, conforme suas caracter√≠sticas de frequ√™ncia e severidade dos sinistros. Em seguida, os dados foram agregados por grupo e ano, somando o total de expostos, frequ√™ncia e sinistros. Por fim, foram calculadas as raz√µes de frequ√™ncia (Freq/Expostos), severidade (Sinist/Freq) e sinistralidade (Sinist/Expostos), permitindo uma an√°lise comparativa entre os diferentes perfis de risco regionais.

# ===========================================
# AGRUPANDO POR GRUPOS TARIFARIOS - k-means
# ===========================================
```{r}
grupoAlt = unique((df_aux2 %>% filter(GrupoTarifario_km == "T3"))$Regiao) # alto indice de colis√£o
grupoMed = unique((df_aux2 %>% filter(GrupoTarifario_km == "T2"))$Regiao) # medio indice de colis√£o
grupoBai = unique((df_aux2 %>% filter(GrupoTarifario_km == "T1"))$Regiao) # baixo indice de colis√£o

df = df_regiao_ano %>%
  mutate(Grupo_Tarifario = case_when(
    Regiao %in% grupoAlt ~ "Alto",
    Regiao %in% grupoMed ~ "Medio",
    Regiao %in% grupoBai ~ "Baixo")) %>%
  group_by(Grupo_Tarifario, Ano) %>%
  summarise(Expostos = sum(Expostos),
            Freq_Total = sum(Freq_Total),
            Ind_Total = sum(Ind_Total)) %>%
  mutate(Frequencia = Freq_Total / Expostos,
         Severidade = case_when(
           Freq_Total > 0 ~ Ind_Total/Freq_Total,
           TRUE ~ 0),
         Razao = Ind_Total / Expostos)
View(df)
```
### Vers√£o Bayesiana do modelo de B√ºhlmann-Straub utilizando k-means
# ======================
# ===== FREQU√äNCIA =====
# ======================

``` {r}
# preparando o stan
## dados para frequ√™ncia
df_freq = df %>%
  filter(Ano != 2020) %>%
  mutate(Razao_Freq = Frequencia)

alto.BSf = df_freq$Razao_Freq[df_freq$Grupo_Tarifario == "Alto"]
medio.BSf = df_freq$Razao_Freq[df_freq$Grupo_Tarifario == "Medio"]
baixo.BSf = df_freq$Razao_Freq[df_freq$Grupo_Tarifario == "Baixo"]

M3 = matrix(c(alto.BSf, medio.BSf, baixo.BSf), byrow = TRUE, ncol = 3)
colnames(M3) = c("2017", "2018", "2019")
rownames(M3) = c("Alto", "Medio", "Baixo")
M3
```

## A frequ√™ncia de sinistros ser√° dada pela contagem de sinistros sobre a exposi√ß√£o, ent√£o ser√° necess√°rio calcular a vari√°vel Raz√£o Frequ√™ncia.

Ser√° considerado o modelo de B√ºhlmann-Straub para modelar a frequ√™ncia de sinistros onde todas as quantidades aleat√≥rias envolvidas s√£o completamente especificadas


(i) $$N_{it}$$ s√£o independentes condicionais a $$\theta_i$$
(ii) $$E[N_{it} \mid \theta_i] = \text{Var}(N_{it} \mid \theta_i) = v_{it} \lambda_0 \theta_i$, onde $\lambda(\theta_i)= \lambda_0 \theta_i$, $\quad j=1:T_i$$

(iii) Definimos  $$F_{it} = N_{it}/v_{it}$$, como a frequ√™ncia do n√∫mero de sinistros.
(iv) Podemos assumir que o n√∫mero de sinistros segue uma distribui√ß√£o Poisson dado por:
$$
N_{it} \sim \text{Poisson}(\lambda_{it}), \quad \lambda_{it} = v_{it} \theta_i \lambda_0
$$

O principal interesse √© obter o Pr√™mio de Credibilidade para o n√∫mero de sinistros, que √© dado por:
$$
\hat{\lambda}_{i} = \omega_i \bar{F}_i + (1 - \omega_i) \lambda_0
$$

onde
$$
\omega_i = \frac{v_i}{v_i + k}
$$

$$k = \frac{1}{\lambda_0} \text{Var}(\theta_i)$$


Sob a abordagem Bayesiana, definem-se as prioris, tal que assumiremos:

$$\begin{aligned}
\theta_i &\sim \text{Gama}(\theta_0, \theta_0) \\
\theta_0 &\sim \text{Gama}(0.001, 0.001)\\
\lambda_0 &\sim \text{Gama}(0.001, 0.001)
\end{aligned}
$$

```{r}

### volume (numero de segurados, por periodo e classe de risco)
alto.BE = df_freq$Expostos[df_freq$Grupo_Tarifario == "Alto"]
medio.BE = df_freq$Expostos[df_freq$Grupo_Tarifario == "Medio"]
baixo.BE = df_freq$Expostos[df_freq$Grupo_Tarifario == "Baixo"]

v = matrix(c(alto.BE,medio.BE,baixo.BE), byrow = TRUE, ncol = 3)
colnames(v) = c("2017","2018","2019")
rownames(v) = c("Alto","Medio","Baixo")
v

### numero de sinistros (sinistros, por periodo e classe de risco)
alto.BF = df_freq$Freq_Total[df_freq$Grupo_Tarifario == "Alto"]
medio.BF = df_freq$Freq_Total[df_freq$Grupo_Tarifario == "Medio"]
baixo.BF = df_freq$Freq_Total[df_freq$Grupo_Tarifario == "Baixo"]

n = matrix(c(alto.BF,medio.BF,baixo.BF), byrow = TRUE, ncol = 3)
colnames(n) = c("2017","2018","2019")
rownames(n) = c("Alto","Medio","Baixo")
n

fi = n/v ### matriz frequencia do num. de sinistros por periodo e classe de risco
m = ncol(fi) ### classes (grupos)
Ti = nrow(fi) ### periodo (anos)

Find = colSums(n)/colSums(v) ### frequencia do numero de sinistros (obitos) Premio Individual √© esse
```
```{r}
stan.lab = "data{   // aqui vc declara qualquer informacao dos dados; definir o tipo de variavel e limites ajuda na eficiencia
  int<lower=1> m;   // numero de grupos
  int<lower=1> Ti; // anos de estudo 
  vector<lower=0>[m] Find;
  int<lower=1> n[Ti,m]; //  numero de obitos por ano e grupo - inteiro
  matrix[Ti,m] v; // exposicao por ano e grupo
  matrix[Ti,m] fi;   // matriz de taxas de mort. por ano e grupo
 }
 
 
parameters{   // 
  vector<lower=0>[m] theta;  // premios de credibilidade para cada grupo
  real<lower=0> theta0;
  real<lower=0> lambda0; //
}


transformed parameters{   // aqui vc declara qualquer parametro que eh funcao de outros
  vector<lower=0>[m] w;   // fator de credibilidade para cada grupo
  vector<lower=0>[m] mucred;  // estimador de credibilidade 
  matrix[Ti,m] lambda;
  // vector<lower=0>[m] lambda;
  
  for(i in 1:m){
     for(t in 1:Ti){
    lambda[t,i] = v[t,i]*theta[i]*lambda0;
     }
}
    for(i in 1:m){
      w[i]=sum(v[,i])/(sum(v[,i])+ (theta0/lambda0)); // fator de credibilidade
      mucred[i]= w[i]*Find[i]+(1-w[i])*lambda0;
  }
} //

model{   // aqui vc define o modelo e as prioris
  // prioris
  for(i in 1:m){
  theta[i] ~ gamma(theta0,theta0); 
  }  // premio cobrado para os i=1,..., m grupos
  lambda0 ~ gamma(0.001, 0.001);
  theta0 ~ gamma(0.001,0.001);
  // verossimilhanca
  for(i in 1:m){  // grupo
   for(t in 1:Ti){ // anos 
      n[t,i] ~ poisson(lambda[t,i]);  //
    // n[t,i] ~ poisson(lambda[i]);  //
    } //
  }
} //  a ultima linha √© sempre em branco
"

stan.dados <- list(v=v,n=n, fi=fi, m=m, Ti=Ti, Find=Find)   # dados que entram no modelo

amostras <- stan(model_code = stan.lab,
                 data = stan.dados,
                 warmup=10000,
                 iter=30000,
                 thin=30,
                 chains=2)

```

A implementa√ß√£o foi realizada em linguagem Stan, utilizando o algoritmo HMC (Hamiltonian Monte Carlo). Foram adotadas 10.000 itera√ß√µes por cadeia, com descarte de 30.000 para *warmup*, al√©m de um *thin* de 30 e duas cadeias em paralelo. 


```{r}

#### extraindo as cadeias

s.post2 <- extract(amostras)  

theta.s <- s.post2$theta
w.s <- s.post2$w 

colnames(theta.s) <- c('Alto', 'Medio', 'Baixo')
colnames(w.s) <- c('Alto', 'Medio', 'Baixo')

### tra√ßo da cadeia de theta

color_scheme_set("brightblue")
mcmc_trace(theta.s)+ theme_bw() +theme(legend.position = "bottom")
mcmc_trace(w.s) + theme_bw() + theme(legend.position = "bottom")

# avalia converg√™ncia das cadeias do MCMC

summary(amostras)$summary[, "Rhat"]

## calculando o erro padr√£o
std.error.post<- apply(s.post2$theta, 2, sd)
std.error.post

```
Os par√¢metros theta e w obtidos por meio da simula√ß√£o MCMC representam, respectivamente, os fatores de risco espec√≠ficos de cada grupo e os fatores de credibilidade associados a esses grupos.*

Par√¢metro theta: O vetor theta cont√™m os fatores de risco espec√≠ficos estimados para cada grupo tarif√°rio especificado (Alto, M√©dio e Baixo). Tais valores indicam o quanto cada grupo se desvia do risco m√©dio da popula√ß√£o. Por exemplo, um valor de theta maior que 1 sugere que o grupo possui um risco maior que a m√©dia, enquanto um valor menor que 1 indica um risco menor.

Os resultados dos par√¢metros mostram que os valores medianos de theta ultrapassam 1 para o grupo Alto e est√£o abaixo de 1 para os grupos M√©dio e Baixo. Isso indica que o grupo Alto t√™m um risco acima da m√©dia, enquanto os grupos M√©dio e Baixo possuem um risco inferior.

O vetor w representa os fatores de credibilidade para cada grupo, calculados com base na variabilidade dos dados dentro e entre os grupos. Valores de w pr√≥ximos de 1 indicam alta credibilidade nas estimativas espec√≠ficas do grupo, enquanto valores pr√≥ximos de 0 sugerem que h√° maior confian√ßa na m√©dia coletiva.

Ao observar os valores de w obtidos por meio das cadeias, v√™-se que para os Grupos Tarif√°rios Alto e M√©dio est√£o sendo utilizadas a experi√™ncia coletiva e individual com pesos similares. J√° para o Grupo Tarif√°rio Alto, a experi√™ncia individual tem um maior efeito em compara√ß√£o √† m√©dia coletiva.

Em rela√ß√£o aos erros padr√£os os valores dos erros obtidos para os par√¢metrosùúÉnos grupos "Alto", "M√©dio" e "Baixo" representam a incerteza associada √†s estimativas desses par√¢metros. Especificamente, os erros indicam o grau de variabilidade esperado nas estimativas de ùúÉ se m√∫ltiplas amostras fossem extra√≠das da mesma popula√ß√£o. Quanto menor o erro padr√£o, maior a precis√£o da estimativa.

Os erros padr√£os obtidos para os Grupos tarif√°rios Alto, M√©dio e Baixo podem ser consultados na tabela std.error.post. Esses valores sugerem que as estimativas de ùúÉ para os tr√™s grupos possuem n√≠veis de precis√£o relativamente semelhantes, com o grupo "Baixo" apresentando uma precis√£o ligeiramente maior.

```{r}

## densidade a posteriori
color_scheme_set("brightblue")
colnames(w.s)<- c('Alto', 'M√©dio', 'Baixo')
mcmc_areas(w.s, prob=0.95, point_est="mean")+ theme_bw() +
  labs(x = "frequencia de sinistro", y = "grupos de risco", title = NULL) 

## intervalos de credibilidade de 95%
q025<- function(x){quantile(x,0.025)}
q975<- function(x){quantile(x,0.975)}

summary.post <- data.frame(
  Pbayes  = apply(s.post2$theta, 2, function(x) median(s.post2$lambda0 * x)),
  lowerIC = apply(s.post2$theta, 2, function(x) quantile(s.post2$lambda0 * x, 0.025)),
  upperIC = apply(s.post2$theta, 2, function(x) quantile(s.post2$lambda0 * x, 0.975))
)
summary.post

### estimativa pontual a posteriori e intervalo de credibilidade
color_scheme_set("brightblue")
mcmc_intervals(theta.s, point_est="mean", inner_size=0.025, outer_size=0.975) + theme_bw() +
  labs(x = "grupos de risco", y = "valor do sinistro", title = "Pr√™mio de Bayes (IC 95%)") +
  geom_point(aes(x=summary.post$Pbayes,y=3:1), col="lightgreen", size=3) 


### autocorrelacao das cadeias
acf(s.post2$w[,1])
acf(s.post2$w[,2])
acf(s.post2$w[,3])
acf(s.post2$theta[,1])
acf(s.post2$theta[,2])
acf(s.post2$theta[,3])
acf(s.post2$theta0)

### estimativa pontual 
summary(s.post2$w[,1])  ### Pcred.1 bayes
summary(s.post2$w[,2])  ### Pcred.2 bayes
summary(s.post2$w[,3])  ### Pcred.3 bayes

summary(s.post2$theta[,1])
summary(s.post2$theta[,2])
summary(s.post2$theta[,3])

summary(s.post2$theta0)  

boxplot(t(M3), ylab="valor pago", cex=1.5, cex.lab=1.5,cex.axis=1.5)

# calculando os pr√™mios de credibilidade e premio individual para frequ√™ncia

Pcred1_freq = (s.post2$lambda0) *  (s.post2$theta[,1]) 
Pcred2_freq = (s.post2$lambda0) *  (s.post2$theta[,2]) 
Pcred3_freq = (s.post2$lambda0) *  (s.post2$theta[,3]) 

summary(Pcred1_freq)
summary(Pcred2_freq)
summary(Pcred3_freq)

# extraindo as medianas para tabelar e calcular pr√™mio individual

Pcred1_freq1 = median(Pcred1_freq)
Pcred2_freq2 = median(Pcred2_freq)
Pcred3_freq3 = median(Pcred3_freq)

# Intervalos de confian√ßa de 95% para pr√™mio de frequ√™ncia (credibilidade full Bayes)
IC_freq <- matrix(NA, ncol = 2, nrow = 3)
colnames(IC_freq) <- c("lower_IC", "upper_IC")
rownames(IC_freq) <- c("Grupo1", "Grupo2", "Grupo3")

for (i in 1:3) {
  amostras_premio <- s.post2$lambda0 * s.post2$theta[, i]
  IC_freq[i, ] <- quantile(amostras_premio, probs = c(0.025, 0.975))
}
IC_freq

# calculando os fatores de credibilidade para frequ√™ncia

w1_freq = median(s.post2$w[,1])
w2_freq = median(s.post2$w[,2])
w3_freq = median(s.post2$w[,3])

w_freq=c(w1_freq,w2_freq,w3_freq)
w_freq

# calculando o pr√™mio coletivo para frequ√™ncia

Pcol_freq = median(s.post2$lambda0)

# calculando os pr√™mios individuais

Pind1_freq = (Pcred1_freq1 - (1-w1_freq)*Pcol_freq)/w1_freq
Pind2_freq = (Pcred2_freq2 - (1-w2_freq)*Pcol_freq)/w2_freq
Pind3_freq = (Pcred3_freq3 - (1-w3_freq)*Pcol_freq)/w3_freq

# Resultado tabelado

df_freq <- summary.post %>% mutate(
  Grupo = c("Alto", "M√©dio", "Baixo"),
  Premio_Individual = c(Pind1_freq, Pind2_freq, Pind3_freq),
  Premio_Coletivo = rep(Pcol_freq, 3),
  Premio_Credibilidade = Pbayes
) %>% select(Grupo, Premio_Individual, Premio_Coletivo, Premio_Credibilidade, lowerIC, upperIC)
df_freq

```
A densidade a posteriori tem um comportamento de distibui√ß√£o poisson-gama, conforme distribui√ß√µes a priori consideradas para a modelagem da frequ√™ncia de sinsitros.

A densidade a posteriori oferece uma vis√£o completa da incerteza e variabilidade dos par√¢metros ap√≥s a an√°lise dos dados, e o summary.post fornece um resumo quantitativo dessa informa√ß√£o para facilitar a interpreta√ß√£o e a tomada de decis√µes. O summary post apresentado mostra o Premio de Bayes, que √© a m√©dia da distribui√ß√£o a posteriori para o par√¢metro Œ∏ de cada grupo e os seus limites m√≠nimos e m√°ximos do intervalo de credibilidade de 95% para Œ∏. Isso significa que h√° uma probabilidade de 95% de que o verdadeiro valor de Œ∏ esteja dentro desse intervalo, tendo em vista os dados observados e a distribui√ß√£o a priori assumida. A tabela tamb√©m classifica os Pr√™mios de Bayes e os seus respectivos intervalos por classe de Risco Alto, M√©dio e Baixo dos Grupos Tarif√°rios.

Em rela√ß√£o √†s autocorrela√ß√µes de theta, os gr√°ficos de autocorrela√ß√£o mostram uma queda r√°pida para valores pr√≥ximos de zero, indicando que a cadeia est√° se misturando bem e fornecendo estimativas precisas para theta, pois uma autocorrela√ß√£o baixa sugere que as amostras s√£o menos dependentes entre si. J√° para o fator de credibilidade (w), os gr√°ficos mostram que h√° uma baixa autocorrela√ß√£o, logo, a cadeia est√° explorando eficientemente o espa√ßo amostral para w, resultando em estimativas mais confi√°veis j√° que as amostras de w s√£o aproximadamente independentes. 

As estimativas pontuais para w e para theta apresentam os instantes amostrais dos par√¢metros para os 3 grupos tarif√°rios: Alto, M√©dio e Baixo. Para w pode-se notar que a mediana e a m√©dia do grupo tarif√°rio baixo √© ligeiramente superior a do grupo m√©dio, que √© ligeiramente superior √† m√©dia e mediana do grupo tarif√°rio alto. J√° para os par√¢metros theta, as medianas e m√©dia apresentam comportamentos que seguem o comportamento dos agrupamentos de Risco, sendo o theta 1 maior que o 2 e o theta 3 maior que o 2. Em rela√ß√£o ao theta 0, observam-se valores de instantes amostrais mais altos, por refletir uma m√©dia global do par√¢metro theta no modelo.

Os fatores de credibilidade n√£o s√£o muito pr√≥ximos a 1, o que indica o peso atribu√≠do √† experi√™ncia individual de cada grupo na estimativa do pr√™mio de seguro, em compara√ß√£o com a m√©dia coletiva. √â poss√≠vel notar que o fator de credibilidade √© maior para o Grupo tarif√°rio de Baixo Risco em compara√ß√£o aos de M√©dio e Alto Risco. Al√©m disso, com fatores de credibilidade n√£o t√£o altos, os pr√™mios de credibilidade calculados para cada grupo est√£o muito pr√≥ximos dos pr√™mios baseados de forma proporcional √† experi√™ncia individual do grupo e √† m√©dia coletiva.

### Vers√£o Bayesiana do modelo de B√ºhlmann-Straub considerando o k-means


Os premios de frequ√™ncia-severidade individual e de credibilidade podem ser obtidos por 
$$\mu_{\theta_i}\lambda_{\theta_i}$$ para cada classe de risco (Alta, M√©dia e Baixa): 

``` {r}

# C√°lculo do pr√™mio individual frequ√™ncia-severidade

Pind1_fs= Pind1_freq * Pind1
Pind2_fs = Pind2_freq * Pind2
Pind3_fs = Pind3_freq * Pind3


# C√°lculo do pr√™mio coletivo frequ√™ncia-severidade

Pcol_fs <- Pcol_freq * Pcol
Pcol_fs

# C√°lculo do pr√™mio de credibilidade frequ√™ncia-severidade

Pcred1_fs= Pcred1_freq1 * Pcred1
Pcred2_fs = Pcred2_freq2 * Pcred2
Pcred3_fs = Pcred3_freq3 * Pcred3

# Resultado tabelado

df_fs = data.frame(
  Grupo = c("Alto", "M√©dio", "Baixo"),
  Premio_Individual = c(Pind1_fs, Pind2_fs, Pind3_fs),
  Premio_Coletivo = rep(Pcol_fs, 3),
  Premio_Credibilidade = c(Pcred1_fs, Pcred2_fs, Pcred3_fs)
)
df_fs

```
O c√°lculo do pr√™mio de frequ√™ncia-severidade representa o pr√™mio puro esperado que a seguradora pagar√° por sinistro individual em cada classe de risco, considerando tanto a probabilidade de ocorr√™ncia (frequ√™ncia) quanto o valor m√©dio dos sinistros (severidade). Os valores calculados podem ser observados na tabela df_fs.

Esses valores baseiam-se exclusivamente na experi√™ncia observada de cada grupo. √â poss√≠vel notar que tais valores s√£o ligeiramente maiores que os obtidos pela modelagem do pr√™mio severidade j√° que considera tamb√©m a frequ√™ncia de sinistros dados os expostos por classe de risco no c√°lculo estimado do pr√™mio.

O pr√™mio coletivo foi determinado a partir da multiplica√ß√£o da severidade coletiva (mu0) pela mediana da frequ√™ncia coletiva (lambda0). O resultado reflete o custo m√©dio esperado por sinistro considerando toda a carteira avaliada, sem distin√ß√£o entre os grupos de risco, portanto, √© um valor ligeiramente mais elevado em compara√ß√£o aos pr√™mios individuais obtidos por classe de risco.

Ao comparar os pr√™mios individuais e os pr√™mios de credibilidade nota-se que os pr√™mios de credibilidade s√£o maiores que os pr√™mios individuais para o Grupo Alto e quase iguais para os Grupos de M√©dio e Baixo Risco. Isso deve-se ao pr√™mio coletivo que √© substancialmente maior e influencia o pr√™mio final. Dessa forma, h√° equilibrados fatores de credibilidade e equilibrados pr√™mios de credibilidade em compara√ß√£o aos pr√™mios individuais. Destaca-se tamb√©m que a diferen√ßa entre ambos os pr√™mios √© mais acentuada no Grupo Alto, indicando uma maior influ√™ncia do pr√™mio individual devido ao menor risco coletivo observado nessa classe.

Conclui-se que, os pr√™mios de credibilidade ajustam os pr√™mios individuais considerando a variabilidade e a incerteza associadas a cada grupo, proporcionando uma estimativa mais robusta e equilibrada para a precifica√ß√£o de seguros. Apesar disso, uma experi√™ncia coletiva elevada como a observada pode influenciar de forma consider√°vel o pr√™mio de credibilidade. Poderiam ser adotadas estrat√©gias como aumentar a exposi√ß√£o dos grupos coletando e utilizando mais dados sobre os sinistros a fim de melhorar a precis√£o das estimativas individuais; e a ado√ß√£o de uma segmenta√ß√£o mais assertiva das classes de Riscos, por exemplo dividindo os segurados em grupos mais homog√™neos em termos de risco para obter estimativas mais precisas e reduzir a variabilidade dentro dos grupos.

```{r}
#=================================================================================
# MACHINE LEARNING - Aplica√ß√£o para prever premio frequ√™ncia-severidade individual
#=================================================================================


# ===== RF e XGBoost considerando as distribui√ß√µes de frequ√™ncia e severidade separadamente =====

# Filtrando o ano de teste para os modelos

df2020 = df %>%
  filter(Ano == 2020)
df2020

# Calculando m√©dias globais para inserir como novas vari√°veis nos modelos
media_freq_global <- mean(df$Freq_Total / df$Expostos, na.rm = TRUE)
media_sev_global <- mean(df$Ind_Total / df$Freq_Total, na.rm = TRUE)

# Adicionando vari√°veis ao df_rf
df_rf <- df %>%
  mutate(
    Frequencia = Freq_Total / Expostos,
    Severidade = case_when(Freq_Total > 0 ~ Ind_Total / Freq_Total, TRUE ~ 0),
    Premio_Puro = Ind_Total / Expostos,
    GrupoTarifario_idx = case_when(
      Grupo_Tarifario == "Alto" ~ 1,
      Grupo_Tarifario == "Medio" ~ 2,
      Grupo_Tarifario == "Baixo" ~ 3
    )
  ) %>%
  group_by(GrupoTarifario_idx) %>%
  mutate(
    Freq_esperada = mean(Frequencia, na.rm = TRUE),
    Razao_freq_esp_obs = Frequencia / media_freq_global,
    Var_freq = var(Frequencia, na.rm = TRUE),
    
    Sev_esperada = mean(Severidade, na.rm = TRUE),
    Razao_sev_esp_obs = Severidade / media_sev_global,
    Var_sev = var(Severidade, na.rm = TRUE)
  ) %>%
  ungroup()
  

# ===== 2. Modelo Random Forest para Frequ√™ncia =====
X_freq <- df_rf %>% select(Frequencia, GrupoTarifario_idx, Razao_freq_esp_obs, Var_freq)
set.seed(12)
modeloRf_freq <- randomForest(Frequencia ~ GrupoTarifario_idx,
                              data = X_freq,
                              ntree = 100)


# ===== 3. Modelo Random Forest para Severidade =====
X_sev <- df_rf %>% select(Severidade, GrupoTarifario_idx,Razao_sev_esp_obs, Var_sev)

set.seed(12)
modeloRf_sev <- randomForest(Severidade ~ GrupoTarifario_idx,
                             data = X_sev,
                             ntree = 100)

# ===== 4. Previs√µes para os grupos de 2020 =====
dados_2020 <- data.frame(GrupoTarifario_idx = c(1, 2, 3))

pred_freq <- predict(modeloRf_freq, newdata = dados_2020)
pred_sev  <- predict(modeloRf_sev, newdata = dados_2020)

# Resultados tabelados para Frequencia

df_freq_rf <- df2020 %>%
  select(Grupo_Tarifario, Ano, Frequencia) %>%
  cbind(Esperado_Mod = c(Pcred1_freq1, Pcred3_freq3, Pcred2_freq2), Esperado_RF = pred_freq[c(1,3,2)])
df_freq_rf

# Resultados tabelados para Severidade

df_sev_rf <- df2020 %>%
  select(Grupo_Tarifario, Ano, Severidade) %>%
  cbind(Esperado_Mod = c(Pcred1, Pcred3, Pcred2), Esperado_RF = pred_sev[c(1,3,2)])
df_sev_rf

# Pr√™mio previsto = Frequ√™ncia prevista √ó Severidade prevista
pred_premio <- pred_freq * pred_sev

df2020_filtrado <- df2020 %>%
  filter(Ano == 2020, Grupo_Tarifario %in% c("Alto", "Medio", "Baixo")) %>%
  arrange(factor(Grupo_Tarifario, levels = c("Alto", "Medio", "Baixo")))

# ===== Resultado tabelado observado e o B√ºhlmann-Straub =====
df2020_resultado <- df2020_filtrado %>%
  ungroup() %>%
  mutate(Esperado_RF = pred_premio)
df2020_resultado

# tabela com todos os resultados

comp_RF <- df2020 %>%
  select(Grupo_Tarifario, Ano, Razao) %>%
  arrange(factor(Grupo_Tarifario, levels = c("Alto", "Medio", "Baixo"))) %>%
  ungroup() %>%
  mutate (
    Esperado_Mod = c(Pcred1_fs, Pcred2_fs, Pcred3_fs),
    Esperado_RF = pred_premio[c(1,2,3)]
  )
comp_RF

```

## XGboost para severidade


``` {r}

X1 <- df_rf %>% select(Grupo_Tarifario, Expostos, Severidade, Razao_sev_esp_obs, Var_sev) %>% 
  mutate(GrupoTarifario_idx = case_when(Grupo_Tarifario == "Alto" ~ 1,
                                        Grupo_Tarifario == "Medio" ~ 2,
                                        Grupo_Tarifario == "Baixo" ~ 3)) %>%
  group_by(GrupoTarifario_idx) %>% select(-Grupo_Tarifario) %>% as.matrix()
X1

dados_2020 <- df_rf %>%
  filter(Ano == 2020, Grupo_Tarifario %in% c("Alto", "Medio", "Baixo")) %>%
  arrange(factor(Grupo_Tarifario, levels = c("Alto", "Medio", "Baixo"))) %>%
  select(Expostos, Razao_sev_esp_obs, Var_sev, GrupoTarifario_idx)

### Configurar e treinar o modelo XGBoost
dtrain1 <- xgb.DMatrix(
  data = as.matrix(X1[, -2]),   # Todas as colunas exceto a 2 (label)
  label = X1[, 2]               # Segunda coluna como target
)

params <- list(
  objective = "reg:squarederror",
  eta = 0.1,
  max_depth = 3,
  subsample = 0.7
)

set.seed(12)
modelo_xgb <- xgboost(params = params, data = dtrain1, nrounds = 100, verbose = 0)

pred.xgbsev <- predict(modelo_xgb, newdata = as.matrix(dados_2020))

comp_sev_XGB <- df2020 %>%
  select(Grupo_Tarifario, Ano, Severidade) %>%
  cbind(Esperado_Mod = c(Pcred1, Pcred3, Pcred2), Esperado_RF = pred_sev[c(1,3,2)], Esperado_XGB = pred.xgbsev[c(1,3,2)]) 
comp_sev_XGB



# XGBoost para frequ√™ncia

dados_2020_2 <- df_rf %>%
  filter(Ano == 2020, Grupo_Tarifario %in% c("Alto", "Medio", "Baixo")) %>%
  arrange(factor(Grupo_Tarifario, levels = c("Alto", "Medio", "Baixo"))) %>%
  select(Expostos, Razao_freq_esp_obs, Var_freq, GrupoTarifario_idx)


X2 <- df_rf %>% select(Grupo_Tarifario, Expostos, Frequencia, Razao_freq_esp_obs, Var_freq) %>% 
  mutate(GrupoTarifario_idx = case_when(Grupo_Tarifario == "Alto" ~ 1,
                                        Grupo_Tarifario == "Medio" ~ 2,
                                        Grupo_Tarifario == "Baixo" ~ 3)) %>%
  group_by(GrupoTarifario_idx) %>% select(-Grupo_Tarifario) %>% as.matrix()
X2

dtrain2 <- xgb.DMatrix(
  data = as.matrix(X2[, -2]),   # Todas as colunas exceto a 2 (label)
  label = X2[, 2]               # Segunda coluna como target
)

params <- list(
  objective = "reg:squarederror",
  eta = 0.1,
  max_depth = 3,
  subsample = 0.7
)

set.seed(12)
modelo_xgb <- xgboost(params = params, data = dtrain2, nrounds = 100, verbose = 0)

pred.xgbfreq <- predict(modelo_xgb, newdata = as.matrix(dados_2020_2))

# Resultados tabelados para Frequencia

comp_freq_XGB <- df2020 %>%
  select(Grupo_Tarifario, Ano, Frequencia) %>%
  cbind(Esperado_Mod = c(Pcred1_freq1, Pcred2_freq2, Pcred3_freq3), Esperado_RF = pred_freq[c(1,3,2)], Esperado_XGB = pred.xgbfreq[c(1,3,2)]) 
comp_freq_XGB


# premio frequencia-severidade individual

pred_freq_sev = pred.xgbsev * pred.xgbfreq


# Tabela com todos os resultados

comp <- df2020 %>%
  select(Grupo_Tarifario, Ano, Razao) %>%
  arrange(factor(Grupo_Tarifario, levels = c("Alto", "Medio", "Baixo"))) %>%
  ungroup() %>%
  mutate (
    Esperado_Mod = c(Pcred1_fs, Pcred2_fs, Pcred3_fs),
    Esperado_RF = pred_premio[c(1,2,3)],
    Esperado_XGB = pred_freq_sev[c(1,2,3)]
  )
comp

# Gr√°ficos com todos os resultados


# Criar um dataframe longo (formato tidy)
comp_long <- comp %>%
  mutate(Grupo_Tarifario = factor(Grupo_Tarifario, levels = c("Alto", "Medio", "Baixo"))) %>%
  select(Grupo_Tarifario, Observado = Razao, Esperado_Mod, Esperado_RF, Esperado_XGB) %>%
  pivot_longer(
    cols = -Grupo_Tarifario,
    names_to = "Modelo",
    values_to = "Premio"
  ) %>%
  arrange(Grupo_Tarifario)


# ICs de 95% para severidade

lower95 = apply(s.post$mu, 2, q025)
upper95 = apply(s.post$mu, 2, q975)

IC95sev = data.frame(lower95, upper95)

# ICs de 95% para frequ√™ncia

lower95 = apply(s.post2$theta, 2, function(x) quantile(s.post2$lambda0 * x, 0.025))
upper95 = apply(s.post2$theta, 2, function(x) quantile(s.post2$lambda0 * x, 0.975))

IC95freq = data.frame(lower95, upper95)

# ICs de 95% para o premio frequ√™ncia-severidade

IC95tot = IC95sev * IC95freq
IC95tot

# Gr√°fico com todos os resultados 

comp$Grupo_Tarifario <- factor(comp$Grupo_Tarifario, levels = c("Alto", "Medio", "Baixo"))

ggplot(comp %>% cbind(IC95tot)) +
  theme_bw() +
  labs(colour = "", y = "Premio") +
  geom_pointrange(aes(x = Grupo_Tarifario, y = Esperado_Mod, ymin = `lower95`, ymax = `upper95`, color = "Modelo")) +
  geom_point(aes(x = Grupo_Tarifario, y = Razao, color = "Observado")) +
  geom_point(aes(x = Grupo_Tarifario, y = Esperado_RF, color = "Random Forest"), shape = 4, size = 2) +
  geom_point(aes(x = Grupo_Tarifario, y = Esperado_XGB, color = "XGBoost"), shape = 8, size = 2)

### metricas de compara√ß√£o dos modelos

#res√≠duo
tab_RES <- comp %>% mutate(RES_modelo = Razao - Esperado_Mod,
                RES_RF = Razao - Esperado_RF,
                RES_XGB = Razao - Esperado_XGB) %>%
  select(Grupo_Tarifario, Ano, RES_modelo, RES_RF, RES_XGB) 
tab_RES

### RMSE (raiz do erro quadratico medio)
Tab_RMSE <- comp %>% mutate(RMSE_modelo = (Razao - Esperado_Mod)^2,
                RMSE_RF = (Razao - Esperado_RF)^2,
                RMSE_XGB = (Razao - Esperado_XGB)^2) %>%
  select(RMSE_modelo, RMSE_RF, RMSE_XGB) %>% colMeans() %>% sqrt()
Tab_RMSE

```
Defini√ß√µes:

Random Forest (Floresta Aleat√≥ria) √© um algoritmo de aprendizado de m√°quina supervisionado utilizado tanto para tarefas de classifica√ß√£o quanto de regress√£o. Ele opera construindo m√∫ltiplas √°rvores de decis√£o durante o treinamento e, para realizar previs√µes, combina os resultados dessas √°rvores. No caso de classifica√ß√£o, a previs√£o final √© determinada pela classe mais votada entre as √°rvores, para regress√£o, √© calculada a m√©dia das previs√µes individuais. 

XGBoost (eXtreme Gradient Boosting) √© uma biblioteca de aprendizado de m√°quina de c√≥digo aberto, amplamente utilizada para tarefas de classifica√ß√£o e regress√£o. Ele implementa uma vers√£o otimizada do algoritmo de gradient boosting, que combina m√∫ltiplos modelos fracos, como √°rvores de decis√£o, para formar um modelo preditivo mais robusto e preciso.

Conclus√£o: Ao realizar um teste com modelos de aprendizado supervisionado considerando algoritmos como o Random Forest e o XGBoost, nota-se a partir do gr√°fico que os dois modelos superestimam o premio frequ√™ncia-severidade comparado aos dados reais para o Grupo de Alto Risco, entretanto, os modelos de Bullman-Straub e XGBoost aproximaram-se muito mais dos dados observados para o Grupo M√©dio que o modelo Random Forest. Para o Grupo Tarif√°rio Baixo o modelo XGboost estimou valores de premios frequ√™ncia-severidade mais pr√≥ximos dos valores observados em compara√ß√£o aos modelos Bullman-Straub e Random Forest que superestimaram os pr√™mios.

O erro quadr√°tico m√©dio foi maior para oS modelos Random Forest e Bullman-Straub e menor para o XGboost. Os valores podem ser observados na Tab_RMSE.